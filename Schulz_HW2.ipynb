{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Schulz_HW2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "dEtLdDhFRqEX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "import numpy as np\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D \n",
        "from keras.layers import UpSampling2D, Dropout, Activation, Flatten \n",
        "from keras.layers import LeakyReLU, LSTM, Conv1D, GlobalMaxPooling1D\n",
        "from keras.models import Model, Sequential\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "import keras\n",
        "from keras.applications import VGG16\n",
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import pandas as pd\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CeFo0XdaRqEb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PtcL-_Op15W-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We see that our training data contains 6,000 images of dimension 28x28, while our testing data contains 10,000 images of dimension 28x28. It is also in unit8 format (which we will change).\n"
      ]
    },
    {
      "metadata": {
        "id": "X9c2hYb11usk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "528b9bc5-87d5-4b9e-813f-dc2dc7aa4511"
      },
      "cell_type": "code",
      "source": [
        "print('Train:', x_train.shape, y_train.shape)\n",
        "\n",
        "print('Test:', x_test.shape, y_test.shape)\n",
        "\n",
        "print(x_train.dtype)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: (60000, 28, 28) (60000,)\n",
            "Test: (10000, 28, 28) (10000,)\n",
            "uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0Ykyrn-Kg-6k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#rescale image pixels to values between 0 and 1\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uufUJtJeUOAu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# FOR 2.2\n",
        "#convert images to three channels\n",
        "train_X = np.stack([x_train] *3, axis = -1)\n",
        "test_X = np.stack([x_test] *3, axis = -1)\n",
        "train_X = train_X.reshape(-1, 28,28,3)\n",
        "test_X = test_X.reshape (-1,28,28,3)\n",
        "\n",
        "#resize the images to 48 x 48 for VGG16\n",
        "train_X = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in train_X])\n",
        "test_X = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in test_X])\n",
        "\n",
        "\n",
        "#converting labels to one hot encoded format\n",
        "train_Y_one_hot = np_utils.to_categorical(y_train)\n",
        "test_Y_one_hot = np_utils.to_categorical(y_test)\n",
        "\n",
        "#split train data as train and validation data\n",
        "train_X,valid_X,train_Label,valid_Label = train_test_split(train_X,\n",
        "                                                           train_Y_one_hot,\n",
        "                                                           test_size=0.2,\n",
        "                                                           random_state=13)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HYMTkuL_UMX8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# FOR 1\n",
        "#reshape data from 6,000 x 28 x 28 to single image dimension\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  \n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jBxn2rP-kqE6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1 Autoencoder**"
      ]
    },
    {
      "metadata": {
        "id": "yHVRZogzg-3d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(28, 28, 1))  \n",
        "\n",
        "#compress image for encoding:\n",
        "\n",
        "# 28 x 28 x 16 matrix\n",
        "x = Conv2D(16, kernel_size = (3, 3), activation='relu', padding='same')(input_img)\n",
        "# 14 x 14 x 16 matrix\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "# 14 x 14 x 8 matrix\n",
        "x = Conv2D(8, kernel_size = (3, 3), activation='relu', padding='same')(x)\n",
        "# 7 x 7 x 8 matrix\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "# 7 x 7 x 8 matrix\n",
        "x = Conv2D(8, kernel_size = (3, 3), activation='relu', padding='same')(x)\n",
        "\n",
        "#image is encoded as 4 x 4 x 8 matrix\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# 4 x 4 x 8 matrix\n",
        "x = Conv2D(8, kernel_size =  (3, 3), activation='relu', padding='same')(encoded)\n",
        "# 8 x 8 x 8 matrix\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "# 8 x 8 x 8 matrix\n",
        "x = Conv2D(8, kernel_size = (3, 3), activation='relu', padding='same')(x)\n",
        "# 16 x 16 x 8 matrix\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "# 14 x 14 x 16 matrix\n",
        "x = Conv2D(16, kernel_size = (3, 3), activation='relu')(x)\n",
        "# 28 x 28 x 16 matrix\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "#image is decoded as 28 x 28 x 1 matrix\n",
        "decoded = Conv2D(1, kernel_size = (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "#we use sigmoid activation and binary cross-entropy loss because pixels have \n",
        "#values between 0 and 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j0Wz5BJzpMfm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Over 10 epochs, the validation loss on the autoencoder improved from about 0.328 to about 0.295."
      ]
    },
    {
      "metadata": {
        "id": "mnTzCGuxVdr4",
        "colab_type": "code",
        "outputId": "54c12e52-3fca-49be-97cc-fdd22b63a62d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs = 10,\n",
        "                batch_size = 64,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 15s 248us/step - loss: 0.3457 - val_loss: 0.3282\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.3086 - val_loss: 0.3040\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 13s 216us/step - loss: 0.3015 - val_loss: 0.3043\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.2980 - val_loss: 0.2996\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.2956 - val_loss: 0.3013\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.2937 - val_loss: 0.2968\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.2923 - val_loss: 0.2917\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.2917 - val_loss: 0.2936\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.2907 - val_loss: 0.2949\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.2903 - val_loss: 0.2956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb6cc105a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "NcE78hg3pWpx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The reconstructed images below show that the autoencoder was able to reproduce the general shapes of the clothin items, but could not reproduce nuances such as patterns on the shirts."
      ]
    },
    {
      "metadata": {
        "id": "B3EliM14g-9x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "6c607a36-ed7c-4280-fa30-0d8d781013a9"
      },
      "cell_type": "code",
      "source": [
        "# Reconstructed images\n",
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(1,n):\n",
        "    # original\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # autoencoder reconstruction\n",
        "    ax = plt.subplot(2, n, i + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/gAAADjCAYAAAAxIr9SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFCu3PUysCgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb6cce905c0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "1ReQrTtSvvke",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2 Image Classification **"
      ]
    },
    {
      "metadata": {
        "id": "Yi09weqE9crU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The data has 10 classes between 0 and 9, which describe the type of clothing each image represents."
      ]
    },
    {
      "metadata": {
        "id": "FqQAqa9Q2Lyo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f21ae3e5-ed88-4928-c6b8-900f51555ccd"
      },
      "cell_type": "code",
      "source": [
        "classes = np.unique(y_train)\n",
        "print(classes)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cz4EoVnoTT52",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#convert classes to 10 dimension matrices (one-hot encoding)\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nlPODoZTKQpi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x,valid_x,train_label,valid_label = train_test_split(x_train, y_train, test_size=0.2, random_state=13)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hm7Xa_3rhAAq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2.1 Deep CNN**"
      ]
    },
    {
      "metadata": {
        "id": "dF0oFCxpW-DB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fashion_model = Sequential()\n",
        "\n",
        "'''\n",
        "I will use leaky ReLU because I read in some article somewhere that leaky \n",
        "ReLU corrects the dying ReLU problem over large gradients.\n",
        "\n",
        "I have chosen the kernels to be size 3x3 and the strides to be 1x1 to \n",
        "gradually sub-sample the inputs. I also chose a pool size of 2x2 to \n",
        "downsample gradually.\n",
        "\n",
        "I have chosen valid padding because the most important information in the image\n",
        "will likely be towards the center, not on the perimeter where valid padding will\n",
        "lose some information. \n",
        "\n",
        "For network depth, I chose two layers because I didn't want the model to get\n",
        "too complicated.\n",
        "\n",
        "'''\n",
        "fashion_model.add(Conv2D(32, kernel_size = (3, 3),\n",
        "                         activation='linear',\n",
        "                         input_shape=(28,28,1),\n",
        "                         strides=(1, 1),\n",
        "                         padding='valid'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))\n",
        "fashion_model.add(MaxPooling2D((2, 2),padding='valid'))\n",
        "fashion_model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "fashion_model.add(Conv2D(64, kernel_size = (3, 3), \n",
        "                         activation='linear',\n",
        "                         strides=(1, 1),\n",
        "                         padding='valid'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))\n",
        "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='valid'))\n",
        "fashion_model.add(Dropout(0.25)) \n",
        "\n",
        "\n",
        "# fully connected layer\n",
        "fashion_model.add(Flatten())\n",
        "fashion_model.add(Dense(64, activation='linear'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.5))\n",
        "fashion_model.add(Dropout(0.5))                 \n",
        "fashion_model.add(Dense(len(classes), activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xzWW7HlAp1Zk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The summary of the model shows that we have a total of 121,930 parameters over 13 layers."
      ]
    },
    {
      "metadata": {
        "id": "brAR4kvIkULM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "d185ce10-accb-4f84-f882-4a263754dcf6"
      },
      "cell_type": "code",
      "source": [
        "fashion_model.compile(loss= 'categorical_crossentropy', optimizer = 'Adam', metrics=['accuracy'])\n",
        "fashion_model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 11, 11, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                102464    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 121,930\n",
            "Trainable params: 121,930\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2FHGcozHJSGy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "6107f20e-b294-4c75-dfcb-21def8000602"
      },
      "cell_type": "code",
      "source": [
        "fashion_train = fashion_model.fit(train_x, train_label, batch_size = 64,\n",
        "                                  epochs = 10,verbose=1,validation_data=(valid_x, valid_label))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 11s 221us/step - loss: 0.6613 - acc: 0.7621 - val_loss: 0.4211 - val_acc: 0.8482\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 10s 200us/step - loss: 0.4401 - acc: 0.8433 - val_loss: 0.3538 - val_acc: 0.8735\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 10s 200us/step - loss: 0.3921 - acc: 0.8603 - val_loss: 0.3229 - val_acc: 0.8872\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 10s 201us/step - loss: 0.3564 - acc: 0.8746 - val_loss: 0.3094 - val_acc: 0.8863\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 10s 200us/step - loss: 0.3451 - acc: 0.8762 - val_loss: 0.2968 - val_acc: 0.8936\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 10s 199us/step - loss: 0.3278 - acc: 0.8835 - val_loss: 0.2978 - val_acc: 0.8886\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 10s 199us/step - loss: 0.3178 - acc: 0.8860 - val_loss: 0.2940 - val_acc: 0.8948\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 10s 199us/step - loss: 0.3074 - acc: 0.8890 - val_loss: 0.3119 - val_acc: 0.8858\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 10s 200us/step - loss: 0.3010 - acc: 0.8910 - val_loss: 0.2664 - val_acc: 0.9040\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 10s 199us/step - loss: 0.2937 - acc: 0.8931 - val_loss: 0.2931 - val_acc: 0.8923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0Q2hzLsBJSoN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_eval = fashion_model.evaluate(x_test, y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SrXdbir2qlMl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Over 10 epochs, the model improved from a validation loss and accuracy of about 0.421 and 0.848, to about 0.293 and 0.892, respectively. The model also performed better in terms of accuracy on the validation set than the training set, suggesting the model was not overfitting."
      ]
    },
    {
      "metadata": {
        "id": "6WfZ6NFukgea",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2.2 Transfer Learning**"
      ]
    },
    {
      "metadata": {
        "id": "SK7W_-w1rgbb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The data has already been set up into three channels for VGG16."
      ]
    },
    {
      "metadata": {
        "id": "KQB_KR_ar1dW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The convolutional base has a total of 14,714,688 parameters over 19 layers."
      ]
    },
    {
      "metadata": {
        "id": "oM6Oa0M-W-Gd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "f7946dfb-1330-4191-c683-153926355cd5"
      },
      "cell_type": "code",
      "source": [
        "conv_base = VGG16(weights=\"imagenet\", include_top=False, input_shape=(48, 48, 3))\n",
        "conv_base.trainable = False\n",
        "conv_base.summary()"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 48, 48, 3)         0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V54f1HeTZIJT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2bac4464-5c03-4dd3-c0cb-66a5e0507a1e"
      },
      "cell_type": "code",
      "source": [
        "#extract features from convolutional base\n",
        "train_features = conv_base.predict(np.array(train_X), batch_size=32, verbose=1)\n",
        "test_features = conv_base.predict(np.array(test_X), batch_size=32, verbose=1)\n",
        "val_features = conv_base.predict(np.array(valid_X), batch_size=32, verbose=1)"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48000/48000 [==============================] - 39s 804us/step\n",
            "10000/10000 [==============================] - 8s 797us/step\n",
            "12000/12000 [==============================] - 9s 786us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TttwIkSVZIMb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#flatten extracted features\n",
        "train_features_flat = np.reshape(train_features, (48000, 1*1*512))\n",
        "test_features_flat = np.reshape(test_features, (10000, 1*1*512))\n",
        "val_features_flat = np.reshape(val_features, (12000, 1*1*512))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xJYBM0RlNo3y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_dim=(1*1*512)))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(Dense(len(classes), activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NW1fkkwusqn-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our model with only three layers has a total of 267,786 parameters."
      ]
    },
    {
      "metadata": {
        "id": "QgiEvO47W-JJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "90b5ed66-06c2-4268-fb38-314292facd5e"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_25 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 267,786\n",
            "Trainable params: 267,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OyesKwLAPn6f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer = 'Adam',metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ks5i35wkPn9F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "46b5ff32-aada-4a12-b6a4-15d0d70a6b73"
      },
      "cell_type": "code",
      "source": [
        "#train model with convolutional base features\n",
        "trans_model = model.fit(\n",
        "    train_features_flat,\n",
        "    train_Label,\n",
        "    epochs=10,\n",
        "    validation_data=(val_features_flat, valid_Label))"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 10s 206us/step - loss: 1.8395 - acc: 0.3279 - val_loss: 1.7393 - val_acc: 0.3663\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 9s 184us/step - loss: 1.7025 - acc: 0.3784 - val_loss: 1.6796 - val_acc: 0.3915\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 9s 185us/step - loss: 1.6627 - acc: 0.3882 - val_loss: 1.6479 - val_acc: 0.3987\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 9s 185us/step - loss: 1.6390 - acc: 0.3962 - val_loss: 1.6304 - val_acc: 0.4035\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 9s 184us/step - loss: 1.6202 - acc: 0.4021 - val_loss: 1.6420 - val_acc: 0.4016\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 9s 186us/step - loss: 1.6060 - acc: 0.4071 - val_loss: 1.6336 - val_acc: 0.3953\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 9s 186us/step - loss: 1.5945 - acc: 0.4121 - val_loss: 1.6054 - val_acc: 0.4139\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 9s 187us/step - loss: 1.5862 - acc: 0.4132 - val_loss: 1.6122 - val_acc: 0.4153\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 9s 184us/step - loss: 1.5800 - acc: 0.4150 - val_loss: 1.6059 - val_acc: 0.4125\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 9s 185us/step - loss: 1.5725 - acc: 0.4190 - val_loss: 1.5963 - val_acc: 0.4128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l7FeY-wYvH_X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The transfer learning model improved over 10 epochs from a validation loss and accuracy of about 1.739 and 0.366 to about 1.596 and 0.413, respectively. The training losses and accuracies are similarly poor. Overall, this model performed much worse than the deep CNN in the previous part. \n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "umizuscivngN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3 Text Classification**"
      ]
    },
    {
      "metadata": {
        "id": "jZf9wOafsuuR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#make sure .txt files are in correct folder\n",
        "\n",
        "ben = pd.read_csv('benign-urls.txt', header=None)\n",
        "ben.columns = [\"url\"]\n",
        "ben['ben0_mal1'] = 0 \n",
        "\n",
        "mal = pd.read_csv('malicious-urls.txt', header=None)\n",
        "mal.columns = [\"url\"]\n",
        "mal['ben0_mal1'] = 1\n",
        "\n",
        "#column of ones (malicious) and zeros (bengin) are labels for model\n",
        "\n",
        "url_data = ben.append(mal)\n",
        "url_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "y = list(url_data.pop('ben0_mal1'))\n",
        "X = list(url_data['url'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xv-bZmExYVUA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tokenize urls by character\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(X)\n",
        "url_tokens = tokenizer.texts_to_sequences(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GP-EiC7gc1uw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#pad tokenized urls to be length of longest url\n",
        "max_url = max(len(x) for x in url_tokens)\n",
        "url_tokens = sequence.pad_sequences(url_tokens, max_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pOWKyP_bwAQD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#convert tokens to matrix \n",
        "url_tokens = np.asmatrix(url_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "18yzh2T2wAS6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(url_tokens, y, test_size=0.20, random_state=13)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_z0bnbFjlw6_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3.1 RNN**"
      ]
    },
    {
      "metadata": {
        "id": "YKUsXFzRPn_u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "#embed based on tokens (1 through 44)\n",
        "model.add(Embedding(input_dim=44,\n",
        "                      output_dim=32,\n",
        "                      input_length = max_url))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(LSTM(150,\n",
        "               input_shape=(max_url,44)))\n",
        "\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#sigmoid activation for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dYM3jdXNcGTo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "0a729989-a22a-41cb-e795-f09ec9fc9dd3"
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_16 (Embedding)     (None, 86, 32)            1408      \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 86, 32)            0         \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 150)               109800    \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 250)               37750     \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 149,209\n",
            "Trainable params: 149,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eQ_voAlJeu32",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "The number of samples is highly skewed towards benign urls. \n",
        "We will balance weights to hopefully lower the rate of false negatives.\n",
        "'''\n",
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SBSv51MgZISb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "bf7db292-da8c-4247-bce8-5fcdd5c70e2d"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size = 64, epochs = 10, \n",
        "          validation_data = (X_test, y_test),class_weight=class_weights)"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 53881 samples, validate on 13471 samples\n",
            "Epoch 1/10\n",
            "53881/53881 [==============================] - 217s 4ms/step - loss: 0.0464 - acc: 0.9830 - val_loss: 0.0239 - val_acc: 0.9874\n",
            "Epoch 2/10\n",
            "53881/53881 [==============================] - 217s 4ms/step - loss: 0.0253 - acc: 0.9873 - val_loss: 0.0224 - val_acc: 0.9895\n",
            "Epoch 3/10\n",
            "53881/53881 [==============================] - 218s 4ms/step - loss: 0.0244 - acc: 0.9883 - val_loss: 0.0225 - val_acc: 0.9888\n",
            "Epoch 4/10\n",
            "53881/53881 [==============================] - 216s 4ms/step - loss: 0.0230 - acc: 0.9886 - val_loss: 0.0205 - val_acc: 0.9898\n",
            "Epoch 5/10\n",
            "53881/53881 [==============================] - 218s 4ms/step - loss: 0.0226 - acc: 0.9890 - val_loss: 0.0202 - val_acc: 0.9899\n",
            "Epoch 6/10\n",
            "53881/53881 [==============================] - 217s 4ms/step - loss: 0.0222 - acc: 0.9890 - val_loss: 0.0205 - val_acc: 0.9893\n",
            "Epoch 7/10\n",
            "53881/53881 [==============================] - 217s 4ms/step - loss: 0.0218 - acc: 0.9891 - val_loss: 0.0201 - val_acc: 0.9899\n",
            "Epoch 8/10\n",
            "53881/53881 [==============================] - 216s 4ms/step - loss: 0.0213 - acc: 0.9894 - val_loss: 0.0203 - val_acc: 0.9901\n",
            "Epoch 9/10\n",
            "53881/53881 [==============================] - 217s 4ms/step - loss: 0.0207 - acc: 0.9898 - val_loss: 0.0194 - val_acc: 0.9897\n",
            "Epoch 10/10\n",
            "53881/53881 [==============================] - 216s 4ms/step - loss: 0.0200 - acc: 0.9902 - val_loss: 0.0192 - val_acc: 0.9895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb59a01dc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "metadata": {
        "id": "KD7iUejOW-Lk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_preds_rnn = model.predict(X_test, batch_size=64)\n",
        "y_test_preds_class_rnn = y_test_preds_rnn > 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-WT4VeoWxlnZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The RNN model performed well in terms of accuracy on the validation set. This is not surprising because the data was highly skewed towards one label (benign). The confusion matrix below shows that we have:\n",
        "\n",
        "false positive rate = 0.007\n",
        "\n",
        "true positive rate = 0.993\n",
        "\n",
        "true negative rate = 0.813\n",
        "\n",
        "false negative rate = 0.187\n",
        "\n",
        "The model still struggled with labeling malicious urls as benign.\n"
      ]
    },
    {
      "metadata": {
        "id": "hgmPkzHsjGlF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "96ac22e2-b1cf-4631-fcc2-56d2bba5798c"
      },
      "cell_type": "code",
      "source": [
        "y_test_arr = np.asarray(y_test)\n",
        "pd.crosstab(y_test_arr, y_test_preds_class_rnn[:,0], colnames=['Predicted'], margins=True)\n",
        "\n",
        "#0 is benign, 1 is malicious"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Predicted</th>\n",
              "      <th>False</th>\n",
              "      <th>True</th>\n",
              "      <th>All</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13120</td>\n",
              "      <td>94</td>\n",
              "      <td>13214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>48</td>\n",
              "      <td>209</td>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All</th>\n",
              "      <td>13168</td>\n",
              "      <td>303</td>\n",
              "      <td>13471</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Predicted  False  True    All\n",
              "row_0                        \n",
              "0          13120    94  13214\n",
              "1             48   209    257\n",
              "All        13168   303  13471"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "metadata": {
        "id": "8Ny4shXtl01E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3.2 CNN**"
      ]
    },
    {
      "metadata": {
        "id": "2RmPYXoJfry0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "#embed based on tokens (1 through 44)\n",
        "model.add(Embedding(input_dim=44,\n",
        "                      output_dim=32,\n",
        "                      input_length=max_url))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv1D(filters=64,\n",
        "                 kernel_size=3,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#sigmoid activation for binary classification\n",
        "model.add(Dense(1, activation=\"sigmoid\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uv4ctDM51ycM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The model has 7 layers with a total of 24,117 parameters."
      ]
    },
    {
      "metadata": {
        "id": "0NaXRXNel6tT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "cc0929dd-fe5e-4a59-abc1-bf6b55df8165"
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_17 (Embedding)     (None, 86, 32)            1408      \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 86, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 84, 64)            6208      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_5 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 250)               16250     \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 24,117\n",
            "Trainable params: 24,117\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kKs49jDdl6v9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "efcd0d01-c438-4af2-b20c-6cdf4a1d9618"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size=64, epochs = 10,\n",
        "          validation_data=(X_test, y_test), class_weight=class_weights)"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 53881 samples, validate on 13471 samples\n",
            "Epoch 1/10\n",
            "53881/53881 [==============================] - 9s 169us/step - loss: 0.0730 - acc: 0.9802 - val_loss: 0.0340 - val_acc: 0.9850\n",
            "Epoch 2/10\n",
            "53881/53881 [==============================] - 8s 143us/step - loss: 0.0320 - acc: 0.9863 - val_loss: 0.0226 - val_acc: 0.9896\n",
            "Epoch 3/10\n",
            "53881/53881 [==============================] - 8s 141us/step - loss: 0.0244 - acc: 0.9888 - val_loss: 0.0195 - val_acc: 0.9912\n",
            "Epoch 4/10\n",
            "53881/53881 [==============================] - 8s 141us/step - loss: 0.0223 - acc: 0.9899 - val_loss: 0.0189 - val_acc: 0.9909\n",
            "Epoch 5/10\n",
            "53881/53881 [==============================] - 8s 141us/step - loss: 0.0206 - acc: 0.9906 - val_loss: 0.0237 - val_acc: 0.9892\n",
            "Epoch 6/10\n",
            "53881/53881 [==============================] - 8s 140us/step - loss: 0.0191 - acc: 0.9920 - val_loss: 0.0225 - val_acc: 0.9905\n",
            "Epoch 7/10\n",
            "53881/53881 [==============================] - 8s 140us/step - loss: 0.0184 - acc: 0.9921 - val_loss: 0.0197 - val_acc: 0.9912\n",
            "Epoch 8/10\n",
            "53881/53881 [==============================] - 8s 141us/step - loss: 0.0172 - acc: 0.9925 - val_loss: 0.0182 - val_acc: 0.9918\n",
            "Epoch 9/10\n",
            "53881/53881 [==============================] - 8s 141us/step - loss: 0.0166 - acc: 0.9928 - val_loss: 0.0185 - val_acc: 0.9912\n",
            "Epoch 10/10\n",
            "53881/53881 [==============================] - 8s 140us/step - loss: 0.0160 - acc: 0.9930 - val_loss: 0.0194 - val_acc: 0.9918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb5f3a0bb00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "metadata": {
        "id": "xKtlVOn7l6yg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_preds_cnn = model.predict(X_test, batch_size=64)\n",
        "y_test_preds_class_cnn = y_test_preds_cnn > 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5_MrCplo2aTk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The CNN model performed well in terms of accuracy on the validation set, similar to the RNN model. The confusion matrix below shows that we have:\n",
        "\n",
        "false positive rate = 0.005\n",
        "\n",
        "true positive rate = 0.995\n",
        "\n",
        "true negative rate = 0.817\n",
        "\n",
        "false negative rate = 0.183\n",
        "\n",
        "Overall, the rates indicate that the CNN model performed slightly better than the RNN model. "
      ]
    },
    {
      "metadata": {
        "id": "Rxj2nRuYnGI3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "2ee5782b-7642-46c9-80cd-466cb72eab7e"
      },
      "cell_type": "code",
      "source": [
        "pd.crosstab(y_test_arr, y_test_preds_class_cnn[:,0], colnames=['predicted'], margins=True)"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>predicted</th>\n",
              "      <th>False</th>\n",
              "      <th>True</th>\n",
              "      <th>All</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13151</td>\n",
              "      <td>63</td>\n",
              "      <td>13214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>47</td>\n",
              "      <td>210</td>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All</th>\n",
              "      <td>13198</td>\n",
              "      <td>273</td>\n",
              "      <td>13471</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "predicted  False  True    All\n",
              "row_0                        \n",
              "0          13151    63  13214\n",
              "1             47   210    257\n",
              "All        13198   273  13471"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 251
        }
      ]
    },
    {
      "metadata": {
        "id": "DJlVLOhJl5Yj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3.3 ROC**"
      ]
    },
    {
      "metadata": {
        "id": "whMs5RPQl7BS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fpr_rnn, tpr_rnn, thresholds_rnn = roc_curve(y_test, y_test_preds_rnn)\n",
        "auc_rnn = auc(fpr_rnn, tpr_rnn)\n",
        "\n",
        "fpr_cnn, tpr_cnn, thresholds_cnn = roc_curve(y_test, y_test_preds_cnn)\n",
        "auc_cnn = auc(fpr_cnn, tpr_cnn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zY21GUFO3U_I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "49d8b109-113b-403e-e51a-e91828c5b29f"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(fpr_rnn, tpr_rnn, label='RNN (area = {:.3f})'.format(auc_rnn))\n",
        "plt.plot(fpr_cnn, tpr_cnn, label='CNN (area = {:.3f})'.format(auc_cnn))\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb59b1596a0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "X8hJUcVlEXkY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The ROC curve shows the models performed very well in detecting the benign urls."
      ]
    }
  ]
}